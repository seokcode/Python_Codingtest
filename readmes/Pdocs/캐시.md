# 캐시
> **18' kakao 공채**  
> [카카오 1차 코테 문제 해설](https://tech.kakao.com/2017/09/27/kakao-blind-recruitment-round-1/)
>
> **Lv2**
>
> **2020-03-06**
>
> [프로그래머스: 17680](https://programmers.co.kr/learn/courses/30/lessons/17680)


## Sol

캐시 교체 알고리즘 중 하나인 LRU(Least Recently Used)를 이용하면 크게 어렵지 않은 문제이다.  
> 'LRU'는 페이지 교체 알고리즘의 종류로 페이지 부재가 발생했을 경우 가장 오랫동안 사용되지 않은 페이지를 제거하는 알고리즘이다. 
> 이 알고리즘은 가장 오래동안 사용되지 않은 페이지는 앞으로도 사용할 확률이 적다는 가정 하에 사용한다.


1. 참조하는 값이 캐시안에 없을 경우 **(cache miss)**
    - cacheSize만큼 차 있다면 가장 오래 전에 참조한 값을 빼고 현재 값을 캐시에 넣어준다
    - 그렇지 않다면 현재 값을 그냥 캐시에 넣어준다
2. 반대로 참조하는 값이 캐시안에 있으면 해당 값을 캐시의 가장 최근 위치에 넣어준다 **(cache hit!)**
 

## 답안
```python
def solution(cacheSize, cities):
    answer = 0
    cache = []
    
    for city in cities:
        city = city.lower() # 대,소문자 구분x
        if not city in cache:
            # cache miss
            answer += 5
            if len(cache) < cacheSize:
                cache.append(city)
            elif cacheSize != 0:
                cache.pop(0)
                cache.append(city)
        else:
            # cache hit
            answer += 1
            cache.pop(cache.index(city))
            cache.append(city)
    
    return answer
```

## Other's Sol
> deque의 maxlen을 활용하여 cache 배열의 크기를 고려하는 불필요한 과정을 줄여주었다. 
```python
def solution(cacheSize, cities):
    import collections
    cache = collections.deque(maxlen=cacheSize)
    time = 0
    for i in cities:
        s = i.lower()
        if s in cache:
            cache.remove(s)
            cache.append(s)
            time += 1
        else:
            cache.append(s)
            time += 5
    return time

```